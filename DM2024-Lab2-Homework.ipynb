{
 "cells": [
  {
   "attachments": {
    "89943587-7c33-4bba-ab2e-e94fd84788fa.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:陳玟卉\n",
    "\n",
    "Student ID:D1114242002\n",
    "\n",
    "GitHub ID:Alice9303\n",
    "\n",
    "Kaggle name:alice0329\n",
    "\n",
    "Kaggle private scoreboard snapshot:![image.png](attachment:89943587-7c33-4bba-ab2e-e94fd84788fa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#take home 1\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Answer here\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import seaborn objects\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\rcmod.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Control plot style and scaling using the matplotlib rcParams interface.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m palettes\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:159\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\colors.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\ticker.py:144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    146\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    148\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    157\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "#take home 1\n",
    "# Answer here\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming train_df and test_df are already loaded as DataFrames\n",
    "# And they contain a 'text' column for text data\n",
    "\n",
    "# 1. Extract text data\n",
    "train_texts = train_df['text']  # Text data from the training set\n",
    "test_texts = test_df['text']    # Text data from the test set\n",
    "\n",
    "# 2. Use CountVectorizer to compute term frequencies\n",
    "count_vect = CountVectorizer()\n",
    "train_term_matrix = count_vect.fit_transform(train_texts)  # Term frequency matrix for the training set\n",
    "test_term_matrix = count_vect.transform(test_texts)        # Term frequency matrix for the test set\n",
    "\n",
    "# 3. Compute the total frequency of each term\n",
    "train_term_frequencies = train_term_matrix.sum(axis=0).A1  # Term frequencies for the training set\n",
    "test_term_frequencies = test_term_matrix.sum(axis=0).A1    # Term frequencies for the test set\n",
    "\n",
    "# 4. Extract words and their frequencies, and sort them by frequency\n",
    "feature_names = count_vect.get_feature_names_out()\n",
    "train_freq_df = pd.DataFrame({'word': feature_names, 'frequency': train_term_frequencies})\n",
    "test_freq_df = pd.DataFrame({'word': feature_names, 'frequency': test_term_frequencies})\n",
    "\n",
    "# Sort by frequency and get the top 30 words\n",
    "train_top30 = train_freq_df.nlargest(30, 'frequency')\n",
    "test_top30 = test_freq_df.nlargest(30, 'frequency')\n",
    "\n",
    "# 5. Plot the top 30 word frequencies in the training set\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=train_top30['word'], y=train_top30['frequency'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Top 30 Word Frequencies in Train Dataset\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot the top 30 word frequencies in the test set\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=test_top30['word'], y=test_top30['frequency'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Top 30 Word Frequencies in Test Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 2\n",
    "# Answer here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# 假设数据已经加载到 train_df 中\n",
    "# train_df = pd.read_csv('train5.csv')  # 如果需要，加载数据\n",
    "\n",
    "# 创建具有 1000 个特征的 TF-IDF 分析器\n",
    "tfidf_1000 = TfidfVectorizer(max_features=1000, tokenizer=nltk.word_tokenize)\n",
    "\n",
    "# 对训练数据进行拟合\n",
    "tfidf_1000.fit(train_df['text'])\n",
    "\n",
    "# 将训练数据转换为 TF-IDF 特征\n",
    "train_data_TFIDF_features_1000 = tfidf_1000.transform(train_df['text'])\n",
    "\n",
    "# 获取特征名称\n",
    "feature_names = tfidf_1000.get_feature_names_out()\n",
    "\n",
    "# 查看特征名称索引 100 到 110 的内容\n",
    "print(\"Feature names from index 100 to 110:\", feature_names[100:111])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 3\n",
    "# Answer here\n",
    "Fear is the most accurately predicted class, with 76 correct predictions, indicating that the model performs well in identifying this emotion.\n",
    "Anger and Sadness have a noticeable number of misclassifications, especially where anger is misclassified as fear (18 times) and sadness as fear (13 times). This suggests some overlap or similarity in features that the model finds confusing between these emotions.\n",
    "Joy has a few errors distributed across other emotions, particularly with predictions as fear (9 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 4\n",
    "# Answer here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "NB_model = MultinomialNB()\n",
    "\n",
    "NB_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred = NB_model.predict(X_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = NB_model.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy for both training and testing sets\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Detailed classification report on test data\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 5\n",
    "# Answer here\n",
    "Model Complexity:\n",
    "\n",
    "Naive Bayes: This is a low-variance, high-bias model due to its strong assumption of feature independence. It’s simple, which makes it less flexible but generally robust to overfitting.\n",
    "Decision Trees: These are high-variance, low-bias models capable of capturing complex patterns, but this complexity often leads to overfitting, particularly when the tree depth is not limited.\n",
    "Independence Assumption:\n",
    "\n",
    "Naive Bayes benefits when features are roughly independent, as the model assumes. Although real-world text data doesn’t strictly meet this assumption, the model’s simplicity helps it handle moderate dependencies without becoming overly complex.\n",
    "Decision Trees, on the other hand, do not assume feature independence and instead seek to capture detailed interactions between features. While this flexibility is powerful, it requires larger datasets or regularization techniques to prevent overfitting.\n",
    "Interpretability of Results:\n",
    "\n",
    "The high training accuracy of the Decision Tree, combined with its lower test accuracy, suggests that it is “memorizing” the training data rather than learning generalizable patterns.\n",
    "Naive Bayes, with its simpler approach, provides more consistent results between training and testing. The lower training accuracy of Naive Bayes reflects its general tendency to create broad decision boundaries, which can be advantageous in high-dimensional settings like text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 6\n",
    "# Answer here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_valid_accuracy(df):\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df['epoch'], df['accuracy'], label='Training Accuracy', color='blue')\n",
    "    plt.plot(df['epoch'], df['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df['epoch'], df['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_train_valid_accuracy(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 7\n",
    "# Answer here\n",
    "word2tfidf = dict(zip(TFIDF_1000.get_feature_names_out(), TFIDF_1000.idf_))\n",
    "\n",
    "# Generate weighted sentence vector\n",
    "sentence = \"I am very happy today\"\n",
    "words = sentence.split()\n",
    "vectors = [w2v_google_model[word] * word2tfidf.get(word, 1) for word in words if word in w2v_google_model]\n",
    "\n",
    "if vectors:\n",
    "    sentence_vector = np.mean(vectors, axis=0)\n",
    "else:\n",
    "    sentence_vector = np.zeros(w2v_google_model.vector_size)\n",
    "\n",
    "print(\"Weighted sentence vector:\", sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 8\n",
    "# Answer here\n",
    "word_list = ['angry', 'happy', 'sad', 'fear']\n",
    "\n",
    "topn = 15\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]        \n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
    "sad_words = ['sad'] + [word_ for word_, sim_ in w2v_google_model.most_similar('sad', topn=topn)]        \n",
    "fear_words = ['fear'] + [word_ for word_, sim_ in w2v_google_model.most_similar('fear', topn=topn)]        \n",
    "\n",
    "print('angry_words: ', angry_words)\n",
    "print('happy_words: ', happy_words)\n",
    "print('sad_words: ', sad_words)\n",
    "print('fear_words: ', fear_words)\n",
    "\n",
    "target_words = angry_words + happy_words + sad_words + fear_words\n",
    "print('\\ntarget words: ')\n",
    "print(target_words)\n",
    "print('total # of target words: ', len(target_words))\n",
    "\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 9\n",
    "# Answer here\n",
    "import ollama\n",
    "\n",
    "user_message = 'Can you tell me what deep learning is? Please give a brief summary in markdown format.'\n",
    "\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': user_message\n",
    "    },\n",
    "])\n",
    "display(Markdown(response['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 10\n",
    "# Answer here\n",
    "response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is this image about?',\n",
    "        'images': ['./pics/cake_stor.jpg'] #Image with the cat\n",
    "    },\n",
    "])\n",
    "\n",
    "display(Markdown(response3['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 11\n",
    "# Answer here\n",
    "import ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "llm_model = \"llama3.2\"  # You can change this to a preferred model\n",
    "\n",
    "# Function to load, split, and retrieve documents from multiple sources\n",
    "def load_and_retrieve_docs(sources, source_type=\"url\"):\n",
    "    documents = []\n",
    "\n",
    "    for source in sources:\n",
    "        if source_type == \"url\":\n",
    "            # Load documents from URLs\n",
    "            loader = WebBaseLoader(web_paths=(source,), bs_kwargs=dict())\n",
    "        elif source_type == \"text\":\n",
    "            # Load documents from local text files\n",
    "            loader = TextFileLoader(filepath=source)\n",
    "        elif source_type == \"pdf\":\n",
    "            # Load documents from PDF files\n",
    "            loader = PyPDFLoader(filepath=source)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported source type. Use 'url', 'text', or 'pdf'.\")\n",
    "\n",
    "        docs = loader.load()\n",
    "        documents.extend(docs)\n",
    "\n",
    "    # Split documents into manageable chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Generate embeddings and create a vector store\n",
    "    embeddings = OllamaEmbeddings(model=llm_model)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "# Define sources (replace these with your own URLs, text files, or PDFs)\n",
    "url_sources = [\n",
    "    \"https://www.ibm.com/topics/large-language-models\",\n",
    "    \"https://en.wikipedia.org/wiki/Natural_language_processing\",\n",
    "    \"https://towardsdatascience.com/transformers-141e32e69591\"\n",
    "]\n",
    "pdf_sources = [\"file1.pdf\", \"file2.pdf\", \"file3.pdf\"]  # Replace with actual PDF file paths\n",
    "text_sources = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]  # Replace with actual text file paths\n",
    "\n",
    "# Create retrievers\n",
    "url_retriever = load_and_retrieve_docs(url_sources, source_type=\"url\")\n",
    "# pdf_retriever = load_and_retrieve_docs(pdf_sources, source_type=\"pdf\")\n",
    "# text_retriever = load_and_retrieve_docs(text_sources, source_type=\"text\")\n",
    "\n",
    "# Function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Define the Ollama LLM function\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model=llm_model, messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_context)\n",
    "\n",
    "# Use the RAG chain with one of the retrievers\n",
    "result = rag_chain(\"What are the key features of transformers in NLP?\", retriever=url_retriever)\n",
    "display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 6\n",
    "# Answer here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_valid_accuracy(df):\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df['epoch'], df['accuracy'], label='Training Accuracy', color='blue')\n",
    "    plt.plot(df['epoch'], df['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df['epoch'], df['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(df['epoch'], df['val_loss'], label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_train_valid_accuracy(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 7\n",
    "# Answer here\n",
    "# Doc2Vec is specifically designed for sentences or documents and is the most direct approach.\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# Example corpus: List of sentences\n",
    "sentences = [\n",
    "    \"I love programming.\",\n",
    "    \"Artificial Intelligence is fascinating.\",\n",
    "    \"Cats are cute.\",\n",
    "    \"Python is a great programming language.\",\n",
    "    \"I hate bugs in my code.\",\n",
    "    \"Debugging is frustrating.\",\n",
    "    \"Dogs are loyal.\",\n",
    "    \"Java is also a popular language.\"\n",
    "]\n",
    "\n",
    "# Preprocessing: Tagging each sentence (required by Doc2Vec)\n",
    "tagged_data = [TaggedDocument(words=sentence.split(), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
    "\n",
    "# Train a Doc2Vec model\n",
    "model = Doc2Vec(vector_size=50,   # Size of sentence embedding\n",
    "                window=2,         # Context window\n",
    "                min_count=1,      # Minimum word frequency\n",
    "                workers=4,        # Number of threads\n",
    "                epochs=20)        # Number of iterations\n",
    "\n",
    "# Build vocabulary and train the model\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Get vector for a sentence\n",
    "sentence_vector = model.infer_vector(\"I love programming.\".split())\n",
    "\n",
    "print(\"Sentence vector:\", sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 8\n",
    "# Answer here\n",
    "word_list = ['angry', 'happy', 'sad', 'fear']\n",
    "\n",
    "topn = 15\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]        \n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
    "sad_words = ['sad'] + [word_ for word_, sim_ in w2v_google_model.most_similar('sad', topn=topn)]        \n",
    "fear_words = ['fear'] + [word_ for word_, sim_ in w2v_google_model.most_similar('fear', topn=topn)]        \n",
    "\n",
    "print('angry_words: ', angry_words)\n",
    "print('happy_words: ', happy_words)\n",
    "print('sad_words: ', sad_words)\n",
    "print('fear_words: ', fear_words)\n",
    "\n",
    "target_words = angry_words + happy_words + sad_words + fear_words\n",
    "print('\\ntarget words: ')\n",
    "print(target_words)\n",
    "print('total # of target words: ', len(target_words))\n",
    "\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## w2v model\n",
    "model = w2v_google_model\n",
    "\n",
    "## prepare training word vectors\n",
    "size = 200\n",
    "target_size = len(target_words)\n",
    "all_word = list(model.index_to_key)\n",
    "word_train = target_words + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "## t-SNE model\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "## training\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "## plot the result\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 9\n",
    "# Answer here\n",
    "import ollama\n",
    "\n",
    "user_message = 'Can you tell me what deep learning is? Please give a brief summary in markdown format.'\n",
    "\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': user_message\n",
    "    },\n",
    "])\n",
    "display(Markdown(response['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 10\n",
    "# Answer here\n",
    "response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is this image about?',\n",
    "        'images': ['./pics/cake_stor.jpg'] #Image with the cat\n",
    "    },\n",
    "])\n",
    "\n",
    "display(Markdown(response3['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 11\n",
    "# Answer here\n",
    "import ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "llm_model = \"llama3.2\"  # You can change this to a preferred model\n",
    "\n",
    "# Function to load, split, and retrieve documents from multiple sources\n",
    "def load_and_retrieve_docs(sources, source_type=\"url\"):\n",
    "    documents = []\n",
    "\n",
    "    for source in sources:\n",
    "        if source_type == \"url\":\n",
    "            # Load documents from URLs\n",
    "            loader = WebBaseLoader(web_paths=(source,), bs_kwargs=dict())\n",
    "        elif source_type == \"text\":\n",
    "            # Load documents from local text files\n",
    "            loader = TextFileLoader(filepath=source)\n",
    "        elif source_type == \"pdf\":\n",
    "            # Load documents from PDF files\n",
    "            loader = PyPDFLoader(filepath=source)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported source type. Use 'url', 'text', or 'pdf'.\")\n",
    "\n",
    "        docs = loader.load()\n",
    "        documents.extend(docs)\n",
    "\n",
    "    # Split documents into manageable chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Generate embeddings and create a vector store\n",
    "    embeddings = OllamaEmbeddings(model=llm_model)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "# Define sources (replace these with your own URLs, text files, or PDFs)\n",
    "url_sources = [\n",
    "    \"https://www.ibm.com/topics/large-language-models\",\n",
    "    \"https://en.wikipedia.org/wiki/Natural_language_processing\",\n",
    "    \"https://towardsdatascience.com/transformers-141e32e69591\"\n",
    "]\n",
    "pdf_sources = [\"file1.pdf\", \"file2.pdf\", \"file3.pdf\"]  # Replace with actual PDF file paths\n",
    "text_sources = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]  # Replace with actual text file paths\n",
    "\n",
    "# Create retrievers\n",
    "url_retriever = load_and_retrieve_docs(url_sources, source_type=\"url\")\n",
    "# pdf_retriever = load_and_retrieve_docs(pdf_sources, source_type=\"pdf\")\n",
    "# text_retriever = load_and_retrieve_docs(text_sources, source_type=\"text\")\n",
    "\n",
    "# Function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Define the Ollama LLM function\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model=llm_model, messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_context)\n",
    "\n",
    "# Use the RAG chain with one of the retrievers\n",
    "result = rag_chain(\"What are the key features of transformers in NLP?\", retriever=url_retriever)\n",
    "display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 12\n",
    "# Answer here\n",
    "plot_train_valid_accuracy(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN is simple but less effective with high-dimensional data like LLM embeddings.\n",
    "Neural Networks can leverage the rich semantic structure of LLM embeddings and fine-tune their representations, leading to superior performance.\n",
    "The choice of model should depend on the task complexity, data dimensionality, and computational constraints. For LLM embeddings, neural networks are generally the more effective choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take home 13\n",
    "# Answer here\n",
    "Impact of Few-Shot Learning:\n",
    "\n",
    "Moving from zero-shot to 5-shot prompting demonstrates a gradual improvement in performance, especially for well-defined emotions like anger and joy.\n",
    "Few-shot examples help ground the model in task-specific nuances, though improvement is limited by inherent overlaps in some emotions.\n",
    "Class-Specific Behavior:\n",
    "\n",
    "Anger: The most consistently predicted emotion across all settings, likely because it has distinct patterns in the embeddings.\n",
    "Fear and Sadness: Challenging to distinguish, likely due to shared features or lack of sufficient distinctive context in the embeddings.\n",
    "Joy: Reasonably well-classified but exhibits some confusion with sadness in all settings.\n",
    "Embedding and Model Limitations:\n",
    "\n",
    "Pretrained language model embeddings might not perfectly encode subtle distinctions between similar emotions.\n",
    "The classification model might benefit from more examples, improved prompts, or domain-specific fine-tuning of the embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform JSON data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames, each representing processed data from a JSON chunk.\n",
    "dfs = []\n",
    "\n",
    "# Read the JSON file using pandas' read_json function with the following parameters:\n",
    "# - 'lines=True': Each line in the file represents a separate JSON object.\n",
    "# - 'chunksize=1000': Process the file in chunks of 1000 rows at a time for memory efficiency.\n",
    "json_chunks = pd.read_json(\n",
    "    '/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json',\n",
    "    lines=True,\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "# Iterate over each chunk of JSON data using enumerate to track the index and content of the chunk.\n",
    "for i, chunk in enumerate(json_chunks):\n",
    "    # Use json_normalize to flatten the JSON structure and extract data from the '_source' field.\n",
    "    df = pd.json_normalize(chunk['_source'])\n",
    "    \n",
    "    # Append the flattened DataFrame to the list.\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames (processed chunks) into a single DataFrame.\n",
    "# - axis=0: Concatenate along the rows (vertically).\n",
    "tweets_df = pd.concat(dfs, axis=0)\n",
    "\n",
    "# Rename the columns of the resulting DataFrame to make them more meaningful and readable.\n",
    "tweets_df.columns = ['hashtags', 'tweet_id', 'text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed DataFrame (tweets_df) as a pickle file named 'tweets_DM.pkl'.\n",
    "# - Pickle is a Python-specific binary format for serializing and saving objects.\n",
    "# - This allows the DataFrame to be quickly reloaded later without reprocessing the original JSON file.\n",
    "tweets_df.to_pickle('tweets_DM.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved DataFrame from the pickle file 'tweets_DM.pkl'.\n",
    "# - The pickle file must be located in the current working directory or at the specified path.\n",
    "# - This restores the DataFrame exactly as it was when saved.\n",
    "tweets_df = pd.read_pickle('tweets_DM.pkl')\n",
    "\n",
    "# Display the loaded DataFrame.\n",
    "# - Simply typing the variable name will show its contents, typically the first and last few rows.\n",
    "tweets_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 'data_identification.csv' file into a DataFrame named dataid_df.\n",
    "# - 'encoding=\"utf-8\"': Ensures proper handling of text data encoded in UTF-8.\n",
    "id_df = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv', encoding='utf-8')\n",
    "\n",
    "# Load the 'emotion.csv' file into a DataFrame named emotion_df.\n",
    "# - 'encoding=\"utf-8\"': Handles text encoding properly to avoid decoding errors for non-ASCII characters.\n",
    "emo_df = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv', encoding='utf-8')\n",
    "\n",
    "# Load the 'sampleSubmission.csv' file into a DataFrame named submition_df.\n",
    "# - 'encoding=\"utf-8\"': Ensures proper handling of special characters in the file.\n",
    "sub_df = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/sampleSubmission.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns of the DataFrame sub_df to make them more descriptive and aligned with their purpose.\n",
    "# - 'tweet_id': Represents the unique identifier for each tweet.\n",
    "# - 'emotion': Represents the predicted or labeled emotion for each tweet.\n",
    "sub_df.columns = ['tweet_id', 'emotion']\n",
    "\n",
    "# Display the contents of the renamed DataFrame.\n",
    "# - This outputs the DataFrame in the notebook to verify the column renaming was successful.\n",
    "sub_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge tweets with identification and emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'identification' column of the dataid_df DataFrame.\n",
    "# - This is useful for understanding the distribution of data types or categories in the column.\n",
    "dataid_df['identification'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the tweets_df DataFrame with emo_df (emotion DataFrame) on the 'tweet_id' column.\n",
    "# - This joins the emotion labels with the tweet data using 'tweet_id' as the key.\n",
    "# - By default, this performs an inner join, keeping only rows with matching 'tweet_id' in both DataFrames.\n",
    "train_df = tweets_df.merge(emo_df, on='tweet_id') \\\n",
    "                    .merge(id_df, on='tweet_id')\n",
    "\n",
    "# Display the resulting merged DataFrame, train_df.\n",
    "# - This allows you to verify that the merge operation combined the data as expected.\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot the distribution of categories in a specific column of a DataFrame.\n",
    "# Default column is 'emotion', but this can be adjusted to other columns.\n",
    "def plot_category_distribution(df, column='emotion'):\n",
    "    # Get unique labels (categories) in the specified column.\n",
    "    labels = df[column].unique()\n",
    "    \n",
    "    # Calculate the total number of rows (instances) in the DataFrame.\n",
    "    post_total = len(df)\n",
    "    \n",
    "    # Group the DataFrame by the specified column and count the number of occurrences of each label.\n",
    "    # The 'text' column is used for counting instances, but you could also count other columns.\n",
    "    df_grouped = df.groupby([column]).count()['text']\n",
    "    \n",
    "    # Convert counts into percentages relative to the total number of instances.\n",
    "    df_grouped = df_grouped.apply(lambda x: round(x*100/post_total, 3))\n",
    "\n",
    "    # Create a bar plot to visualize the category distribution.\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))  # Set figure size.\n",
    "    plt.bar(df_grouped.index, df_grouped.values)  # Plot the bars.\n",
    "\n",
    "    # Arrange labels and title for the plot.\n",
    "    plt.ylabel('% of instances')  # Y-axis label indicating percentage.\n",
    "    plt.xlabel(f'{column.capitalize()}')  # X-axis label showing the column name.\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels by 45 degrees for better readability.\n",
    "    plt.title(f'{column.capitalize()} distribution')  # Title of the plot.\n",
    "    plt.grid(True)  # Add grid lines to the plot for better visibility.\n",
    "    \n",
    "    # Show the plot.\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.emotion.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = tweets_df.merge(submition_df, on='tweet_id').merge(dataid_df, on='tweet_id')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating features through the Bag of Words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "# Download punkt\n",
    "try:\n",
    "    nltk.data.find('punkt_tab')\n",
    "except:\n",
    "    nltk.download('punkt_tab', download_dir='/kaggle/working/')\n",
    "    nltk.data.path.append('/kaggle/working/')\n",
    "  \n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_df['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(train_df['text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe some feature names\n",
    "feature_names = BOW_500.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['emotion'] == 'surprise', 'emotion'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For a classification problem, you need to provide both training and testing data.\n",
    "# 'X_train' contains the feature matrix (converted text data) for the training set.\n",
    "# 'y_train' contains the labels (emotions) for the training set.\n",
    "\n",
    "X_train = BOW_500.transform(train_df['text'])  # Convert the training text to feature vectors using Bag of Words (BOW).\n",
    "y_train = train_df['emotion']  # The target labels (emotions) for the training data.\n",
    "\n",
    "# 'X_test' contains the feature matrix for the test set.\n",
    "# 'y_test' contains the true labels for the test set (used for evaluation).\n",
    "\n",
    "X_test = BOW_500.transform(test_df['text'])  # Convert the test text to feature vectors using BOW.\n",
    "y_test = test_df['emotion']  # The target labels (emotions) for the test data.\n",
    "\n",
    "# It’s a good practice to check the dimensions of your data before training a model.\n",
    "# This will ensure that your feature matrix and target labels have the correct shape.\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)  # Print the shape of the training feature matrix.\n",
    "print('y_train.shape: ', y_train.shape)  # Print the shape of the training labels.\n",
    "print('X_test.shape: ', X_test.shape)  # Print the shape of the test feature matrix.\n",
    "print('y_test.shape: ', y_test.shape)  # Print the shape of the test labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time, formatted as 'YYYYMMDD_HHMMSS'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Update the filename with a new name and the timestamp\n",
    "filename = f\"/kaggle/working/new_submission_{timestamp}.csv\"  # Changed the prefix to 'new_submission'\n",
    "\n",
    "# Rest of your code for preparing the submission\n",
    "submission_df = test_df.copy()  # Create a copy of the test DataFrame\n",
    "submission_df.emotion = y_test_pred  # Add the predicted 'emotion' to the DataFrame\n",
    "submission_df.drop(columns=['hashtags', 'text', 'identification'], axis=1, inplace=True)  # Drop unnecessary columns\n",
    "submission_df.columns = ['id', 'emotion']  # Rename columns for the final output\n",
    "submission_df.to_csv(filename, index=False)  # Save the final DataFrame to CSV with the new filename\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
